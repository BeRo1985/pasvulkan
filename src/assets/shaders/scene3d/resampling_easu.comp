#version 450 core

#extension GL_ARB_separate_shader_objects : enable
#extension GL_ARB_shading_language_420pack : enable
#extension GL_GOOGLE_include_directive : enable

// EASU - Edge-Adaptive Spatial Upsampling (FSR1 Pass 1)
//
// This is an edge-adaptive upsampling compute shader inspired by AMD's FidelityFX Super Resolution 1.0.
// It detects local edge direction and strength using luminance gradients from a 4x4 neighborhood,
// then shapes a 12-tap Lanczos2-like filter kernel as a directionally-scaled ellipse aligned to the
// detected edge. Along an edge, the filter is wide (smooth); across an edge, it is narrow (sharp).
// The result is clamped to the min/max of the 4 nearest source texels for anti-ringing.

/* clang-format off */

layout(local_size_x = 16, local_size_y = 16, local_size_z = 1) in;

#ifdef MULTIVIEW
layout(set = 0, binding = 0) uniform sampler2DArray uSourceTexture;
layout(set = 0, binding = 1, rgba16f) writeonly uniform image2DArray uDestinationTexture;
#else
layout(set = 0, binding = 0) uniform sampler2D uSourceTexture;
layout(set = 0, binding = 1, rgba16f) writeonly uniform image2D uDestinationTexture;
#endif

/* clang-format on */

#include "bidirectional_tonemapping.glsl"

#include "srgb.glsl"

#ifdef MULTIVIEW
int viewIndex = int(gl_GlobalInvocationID.z);
#endif

// Approximate Lanczos2 kernel evaluated on squared distance.
// Takes distanceSquared (avoids sqrt per tap) and lobeStrength which
// controls the negative lobe depth (adapts to edge strength).
//
// The approximation factors into two parts:
//   shape:  (25/16) * ((2/5)*distanceSquared - 1)^2 - 9/16
//   window: (lobeStrength * distanceSquared - 1)^2
// Together they produce: 1.0 at distanceSquared=0, proper negative lobe in the [1,2) region,
// and 0.0 beyond distanceSquared=4 (i.e. |d|=2). The lobeStrength parameter tunes how
// deep the negative lobe goes — stronger in flat areas, weaker on edges.
float evaluateKernel(float distanceSquared, float lobeStrength) {
  float shape  = (2.0 / 5.0) * distanceSquared - 1.0;
  float window = lobeStrength * distanceSquared - 1.0;
  shape  *= shape;
  window *= window;
  return ((25.0 / 16.0) * shape - (9.0 / 16.0)) * window;
}

// Cheap luma approximation: R*0.5 + G + B*0.5 (= luma * 2).
// Costs only 2 FMA/MAD, and what matters here is relative contrast,
// not exact perceptual luminance.
float computeLuma(vec3 color) {
  return color.b * 0.5 + (color.r * 0.5 + color.g);
}

// Accumulate edge direction and strength from one bilinear sub-quad.
// Each quad has a cross-shaped 5-sample pattern:
//        top
//   left center right
//       bottom
// We compute horizontal and vertical gradients, but normalize each by
// the maximum one-sided difference. This makes the measurement relative
// to local contrast rather than absolute brightness — a crucial difference
// for robust edge detection across varying exposure levels.
void accumulateEdgeInfo(
  inout vec2 direction,
  inout float edginess,
  float weight,
  float top, float left, float center, float right, float bottom
) {
  // Horizontal: how consistent is the left-to-right gradient?
  float gradientRight       = right - center;
  float gradientLeft        = center - left;
  float maxOneSideHorizontal = max(abs(gradientRight), abs(gradientLeft));
  float totalHorizontal      = right - left;
  direction.x += totalHorizontal * weight;
  // Ratio of total gradient to max one-sided gradient.
  // If gradient reverses (left>center>right vs left<center<right), this goes to 0.
  // If gradient is consistent, this goes to 1.
  float consistencyHorizontal = clamp(abs(totalHorizontal) / max(maxOneSideHorizontal, 1e-6), 0.0, 1.0);
  edginess += consistencyHorizontal * consistencyHorizontal * weight;

  // Vertical: same logic
  float gradientBottom      = bottom - center;
  float gradientTop         = center - top;
  float maxOneSideVertical  = max(abs(gradientBottom), abs(gradientTop));
  float totalVertical       = bottom - top;
  direction.y += totalVertical * weight;
  float consistencyVertical = clamp(abs(totalVertical) / max(maxOneSideVertical, 1e-6), 0.0, 1.0);
  edginess += consistencyVertical * consistencyVertical * weight;
}

// Fetch a source texel using texelFetch, clamped to source dimensions, and apply tone mapping.
// Applies tone mapping (HDR linear → [0,1] linear) followed by linear-to-sRGB conversion,
// so that all filtering happens in perceptual sRGB space.
vec4 fetchSource(ivec2 coordinate, ivec2 sourceSize) {
  coordinate = clamp(coordinate, ivec2(0), sourceSize - ivec2(1));
#ifdef MULTIVIEW
  return convertLinearRGBToSRGB(ApplyToneMapping(texelFetch(uSourceTexture, ivec3(coordinate, viewIndex), 0)));
#else
  return convertLinearRGBToSRGB(ApplyToneMapping(texelFetch(uSourceTexture, coordinate, 0)));
#endif
}

void main() {

#ifdef MULTIVIEW
  ivec3 invocationPosition = ivec3(gl_GlobalInvocationID.xyz);
  ivec3 dstSize = imageSize(uDestinationTexture);
  if (any(greaterThanEqual(invocationPosition, dstSize))) {
    return;
  }
#else
  ivec2 invocationPosition = ivec2(gl_GlobalInvocationID.xy);
  ivec2 dstSize = imageSize(uDestinationTexture);
  if (any(greaterThanEqual(invocationPosition, dstSize))) {
    return;
  }
#endif

  ivec2 destinationCoordinate = invocationPosition.xy;
  ivec2 sourceSize = ivec2(textureSize(uSourceTexture, 0).xy);

  // Compute the source-space position of this destination pixel center.
  // Map destination pixel center -> source continuous coordinates.
  vec2 sourcePosition = (vec2(destinationCoordinate) + vec2(0.5)) * (vec2(sourceSize) / vec2(dstSize.xy)) - vec2(0.5);

  // Integer part: the nearest source texel to the top-left of the 2x2 quad.
  vec2 sourceFloor = floor(sourcePosition);
  // Fractional part: sub-texel position within that quad, in [0,1).
  vec2 fractional = sourcePosition - sourceFloor;
  ivec2 sourceCoordinate = ivec2(sourceFloor);

  // ------------------------------------------------------------------
  // Fetch 12-tap cross neighborhood (4x4 minus the four corners).
  //
  // Layout relative to sourceCoordinate (which sits at position 'F'):
  //      B  C
  //   E  F  G  H
  //   I  J  K  L
  //      N  O
  //
  // F,G,J,K are the 4 nearest texels used for anti-ringing bounds.
  // ------------------------------------------------------------------

  vec4 tapB = fetchSource(sourceCoordinate + ivec2( 0, -1), sourceSize);
  vec4 tapC = fetchSource(sourceCoordinate + ivec2( 1, -1), sourceSize);
  vec4 tapE = fetchSource(sourceCoordinate + ivec2(-1,  0), sourceSize);
  vec4 tapF = fetchSource(sourceCoordinate + ivec2( 0,  0), sourceSize);
  vec4 tapG = fetchSource(sourceCoordinate + ivec2( 1,  0), sourceSize);
  vec4 tapH = fetchSource(sourceCoordinate + ivec2( 2,  0), sourceSize);
  vec4 tapI = fetchSource(sourceCoordinate + ivec2(-1,  1), sourceSize);
  vec4 tapJ = fetchSource(sourceCoordinate + ivec2( 0,  1), sourceSize);
  vec4 tapK = fetchSource(sourceCoordinate + ivec2( 1,  1), sourceSize);
  vec4 tapL = fetchSource(sourceCoordinate + ivec2( 2,  1), sourceSize);
  vec4 tapN = fetchSource(sourceCoordinate + ivec2( 0,  2), sourceSize);
  vec4 tapO = fetchSource(sourceCoordinate + ivec2( 1,  2), sourceSize);

  // Luma for edge detection.
  float lumaB = computeLuma(tapB.rgb), lumaC = computeLuma(tapC.rgb);
  float lumaE = computeLuma(tapE.rgb), lumaF = computeLuma(tapF.rgb);
  float lumaG = computeLuma(tapG.rgb), lumaH = computeLuma(tapH.rgb);
  float lumaI = computeLuma(tapI.rgb), lumaJ = computeLuma(tapJ.rgb);
  float lumaK = computeLuma(tapK.rgb), lumaL = computeLuma(tapL.rgb);
  float lumaN = computeLuma(tapN.rgb), lumaO = computeLuma(tapO.rgb);

  // ------------------------------------------------------------------
  // Edge detection via 4 overlapping cross-patterns.
  //
  // Each cross is centered on one of F, G, J, K and reads the 4
  // cardinal neighbors from the 12-tap set:
  //
  //   Cross centered on F:  top=B, left=E, ctr=F, right=G, bot=J
  //   Cross centered on G:  top=C, left=F, ctr=G, right=H, bot=K
  //   Cross centered on J:  top=F, left=I, ctr=J, right=K, bot=N
  //   Cross centered on K:  top=G, left=J, ctr=K, right=L, bot=O
  //
  // The four crosses are blended with bilinear weights from the
  // sub-texel position, so the result smoothly tracks where the
  // output pixel actually lands.
  // ------------------------------------------------------------------

  vec2 direction = vec2(0.0);
  float edginess = 0.0;

  float weightTopLeft     = (1.0 - fractional.x) * (1.0 - fractional.y);
  float weightTopRight    = fractional.x          * (1.0 - fractional.y);
  float weightBottomLeft  = (1.0 - fractional.x) * fractional.y;
  float weightBottomRight = fractional.x          * fractional.y;

  accumulateEdgeInfo(direction, edginess, weightTopLeft,     lumaB, lumaE, lumaF, lumaG, lumaJ);
  accumulateEdgeInfo(direction, edginess, weightTopRight,    lumaC, lumaF, lumaG, lumaH, lumaK);
  accumulateEdgeInfo(direction, edginess, weightBottomLeft,  lumaF, lumaI, lumaJ, lumaK, lumaN);
  accumulateEdgeInfo(direction, edginess, weightBottomRight, lumaG, lumaJ, lumaK, lumaL, lumaO);

  // ------------------------------------------------------------------
  // Normalize direction, handle near-zero gradient gracefully.
  // ------------------------------------------------------------------

  float directionLengthSquared = dot(direction, direction);
  bool noEdge = directionLengthSquared < (1.0 / 32768.0);
  float inverseDirectionLength = inversesqrt(max(directionLengthSquared, 1e-10));
  // When there's no detectable edge, default to horizontal (arbitrary but stable).
  direction = noEdge ? vec2(1.0, 0.0) : direction * inverseDirectionLength;

  // ------------------------------------------------------------------
  // Compute anisotropic kernel parameters from edge strength.
  //
  // edginess is in [0..2] range (sum of H+V from the weighted quads).
  // We remap it to [0..1] and square to emphasize strong edges.
  // ------------------------------------------------------------------

  float edgeAmount = edginess * 0.5;   // [0..1]
  edgeAmount *= edgeAmount;            // emphasize

  // The kernel stretches from isotropic (circle) to anisotropic (ellipse):
  //   Along the edge direction:  scale goes from 1x to 'stretch'x
  //   Across the edge direction: scale goes from 1x to ~0.5x (tighter)
  //
  // 'stretch' accounts for diagonal directions: when direction is 45°,
  // |dir|² / max(|dir.x|,|dir.y|) = sqrt(2), stretching the kernel
  // slightly to cover the diagonal distance properly.
  float diagonalStretch = dot(direction, direction) / max(abs(direction.x), abs(direction.y));
  vec2 anisotropicScale = vec2(
    1.0 + (diagonalStretch - 1.0) * edgeAmount,  // along-edge: widen
    1.0 - 0.5 * edgeAmount                       // across-edge: tighten
  );

  // Adaptive negative lobe control.
  // In flat areas (edgeAmount≈0), lobeStrength≈0.5 → deeper negative lobe → sharper.
  // On strong edges (edgeAmount≈1), lobeStrength≈0.21 → shallower lobe → smoother.
  float lobeStrength = 0.5 - 0.29 * edgeAmount;

  // Maximum distance² before the tap is considered outside the kernel window.
  // This clips far-away taps (especially on corners) cleanly.
  float maxDistanceSquared = 1.0 / lobeStrength;

  // ------------------------------------------------------------------
  // Accumulate 12 taps through the directional kernel.
  //
  // For each tap, we:
  //  1. Compute the offset from the output pixel to the tap center
  //  2. Rotate into edge-aligned coordinates
  //  3. Apply anisotropic scaling (stretch along edge, compress across)
  //  4. Evaluate the kernel on the squared distance (no sqrt!)
  //  5. Accumulate weighted color
  // ------------------------------------------------------------------

  vec3 accumulatedColor = vec3(0.0);
  float accumulatedWeight = 0.0;

  // Anti-ringing: bounding box from the 4 nearest source texels.
  vec3 nearestMin = min(min(tapF.rgb, tapG.rgb), min(tapJ.rgb, tapK.rgb));
  vec3 nearestMax = max(max(tapF.rgb, tapG.rgb), max(tapJ.rgb, tapK.rgb));

  #define ACCUMULATE_TAP(tapColor, offsetX, offsetY) {                                    \
    vec2 tapOffset = vec2(float(offsetX) - fractional.x, float(offsetY) - fractional.y);  \
    /* Rotate into edge-aligned frame */                                                  \
    vec2 rotatedOffset = vec2(                                                            \
      tapOffset.x * direction.x + tapOffset.y * direction.y,                              \
      tapOffset.x * (-direction.y) + tapOffset.y * direction.x                            \
    );                                                                                    \
    /* Apply anisotropic scaling */                                                       \
    rotatedOffset *= anisotropicScale;                                                    \
    /* Squared distance (no sqrt needed!) */                                              \
    float distanceSquared = min(dot(rotatedOffset, rotatedOffset), maxDistanceSquared);   \
    float tapWeight = evaluateKernel(distanceSquared, lobeStrength);                      \
    accumulatedColor += (tapColor).rgb * tapWeight;                                       \
    accumulatedWeight += tapWeight;                                                       \
  }

  //      B  C          (offsets: B=(0,-1), C=(1,-1))
  //   E  F  G  H       (offsets: E=(-1,0), F=(0,0), G=(1,0), H=(2,0))
  //   I  J  K  L       (offsets: I=(-1,1), J=(0,1), K=(1,1), L=(2,1))
  //      N  O          (offsets: N=(0,2), O=(1,2))

  ACCUMULATE_TAP(tapB,  0, -1)
  ACCUMULATE_TAP(tapC,  1, -1)
  ACCUMULATE_TAP(tapE, -1,  0)
  ACCUMULATE_TAP(tapF,  0,  0)
  ACCUMULATE_TAP(tapG,  1,  0)
  ACCUMULATE_TAP(tapH,  2,  0)
  ACCUMULATE_TAP(tapI, -1,  1)
  ACCUMULATE_TAP(tapJ,  0,  1)
  ACCUMULATE_TAP(tapK,  1,  1)
  ACCUMULATE_TAP(tapL,  2,  1)
  ACCUMULATE_TAP(tapN,  0,  2)
  ACCUMULATE_TAP(tapO,  1,  2)

  #undef ACCUMULATE_TAP

  // Normalize, then clamp to the neighborhood bounding box to prevent ringing.
  vec3 resultColor = clamp(accumulatedColor / max(accumulatedWeight, 1e-6), nearestMin, nearestMax);

  // Bilinearly interpolate alpha from the 4 nearest texels.
  float resultAlpha = mix(mix(tapF.a, tapG.a, fractional.x), mix(tapJ.a, tapK.a, fractional.x), fractional.y);

  // Output stays in sRGB space - RCAS will read it directly and convert back at the end.
  imageStore(uDestinationTexture, invocationPosition, vec4(resultColor, resultAlpha));

}
